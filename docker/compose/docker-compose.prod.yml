name: "mankahi-prod-compose"

networks:
    frontend:
    backend:
    monitoring:

services:
    # Database Initialization Service
    init-db:
        build:
            context: ../../backend
            dockerfile: init-service/Dockerfile
        container_name: mankahi-init-db-prod
        depends_on:
            postgres:
                condition: service_healthy
        env_file:
            - .env
        volumes:
            - ../../backend/shared:/app/shared
        deploy:
            resources:
                limits:
                    cpus: "0.5"
                    memory: 512M
        restart: "no"
        networks:
            - backend
        logging:
            driver: "json-file"
            options:
                max-size: "200m"
                max-file: "5"

    # PostgreSQL with optimized settings
    postgres:
        image: postgres:16-alpine
        container_name: mankahi-postgres-prod
        env_file:
            - .env
        ports:
            - "5432:5432"
        volumes:
            - postgres-data:/var/lib/postgresql/data
            - ../scripts/init-db.sh:/docker-entrypoint-initdb.d/init.sh
        healthcheck:
            test: [ "CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}" ]
            interval: 10s
            timeout: 5s
            retries: 5
        deploy:
            resources:
                limits:
                    cpus: "4"
                    memory: 8G
        command: >
            postgres
            -c shared_buffers=2GB
            -c effective_cache_size=6GB
            -c maintenance_work_mem=512MB
            -c random_page_cost=1.1
            -c effective_io_concurrency=200
            -c work_mem=6553kB
            -c min_wal_size=1GB
            -c max_wal_size=4GB
            -c checkpoint_completion_target=0.9
            -c default_statistics_target=100
            -c max_connections=200
        networks:
            - backend
        stop_grace_period: 1m
        logging:
            driver: "json-file"
            options:
                max-size: "200m"
                max-file: "5"

    # Redis with persistence and optimized settings
    redis:
        image: redis:alpine
        container_name: mankahi-redis-prod
        command: redis-server --appendonly yes --maxmemory 2gb --maxmemory-policy allkeys-lru
        ports:
            - "6379:6379"
        volumes:
            - redis-data:/data
        deploy:
            resources:
                limits:
                    cpus: "2"
                    memory: 4G
        healthcheck:
            test: ["CMD", "redis-cli", "ping"]
            interval: 10s
            timeout: 5s
            retries: 5
        networks:
            - backend
        stop_grace_period: 30s
        logging:
            driver: "json-file"
            options:
                max-size: "200m"
                max-file: "5"

    # MinIO with optimized settings
    minio:
        image: minio/minio
        container_name: mankahi-minio-prod
        ports:
            - "9000:9000"
            - "9001:9001"
        env_file:
            - .env
        environment:
            - MINIO_ROOT_USER=${MINIO_ROOT_USER:-admin}
            - MINIO_ROOT_PASSWORD=${MINIO_ROOT_PASSWORD:-adminpassword}
        volumes:
            - minio-data:/data
        command: server /data --console-address ":9001"
        deploy:
            resources:
                limits:
                    cpus: "2"
                    memory: 4G
        healthcheck:
            test: ["CMD", "mc", "ready", "local"]
            interval: 30s
            timeout: 20s
            retries: 3
        networks:
            - backend
        stop_grace_period: 30s
        logging:
            driver: "json-file"
            options:
                max-size: "200m"
                max-file: "5"

    # Elasticsearch with production settings
    elasticsearch:
        image: docker.elastic.co/elasticsearch/elasticsearch:8.12.0
        container_name: mankahi-elasticsearch-prod
        env_file:
            - .env
        environment:
            - node.name=es01
            - cluster.name=mankahi-es-cluster
            - discovery.type=single-node
            - bootstrap.memory_lock=true
            - ES_JAVA_OPTS=-Xms4g -Xmx4g
            - xpack.security.enabled=true
        ports:
            - "9200:9200"
        volumes:
            - elasticsearch-data:/usr/share/elasticsearch/data
            - ./elasticsearch/config/certs:/usr/share/elasticsearch/config/certs:ro
        deploy:
            resources:
                limits:
                    cpus: "4"
                    memory: 8G
        ulimits:
            memlock:
                soft: -1
                hard: -1
            nofile:
                soft: 65536
                hard: 65536
        healthcheck:
            test: [ "CMD-SHELL", "curl -sf --cacert /usr/share/elasticsearch/config/certs/http_ca.crt https://localhost:9200/_cluster/health?wait_for_status=yellow&timeout=60s" ]
            interval: 30s
            timeout: 10s
            retries: 5
        networks:
            - backend
        stop_grace_period: 1m
        logging:
            driver: "json-file"
            options:
                max-size: "200m"
                max-file: "5"

    # Auth Service
    auth-service:
        build:
            context: ../../backend
            dockerfile: auth-service/Dockerfile
            target: production
        container_name: mankahi-auth-prod
        restart: unless-stopped
        working_dir: /app/auth-service
        env_file:
            - .env
        environment:
            - NODE_ENV=production
            - PORT=3001
            - RATE_LIMIT_WINDOW=900
            - RATE_LIMIT_MAX_REQUESTS=100
        volumes:
            - ../../backend/shared:/app/shared
        deploy:
            replicas: 2
            update_config:
                parallelism: 1
                delay: 10s
            resources:
                limits:
                    cpus: "1"
                    memory: 1G
        healthcheck:
            test: ["CMD-SHELL", "curl -sf http://localhost:3001/health | grep -q '\"status\":\"healthy\"'"]
            interval: 30s
            timeout: 10s
            retries: 3
            start_period: 40s
        depends_on:
            init-db:
                condition: service_completed_successfully
            postgres:
                condition: service_healthy
            redis:
                condition: service_healthy
            analytics-service:
                condition: service_healthy
        ports:
            - "3001:3001"
        networks:
            - backend
        stop_grace_period: 30s
        logging:
            driver: "json-file"
            options:
                max-size: "200m"
                max-file: "5"

    # Blog Service
    blog-service:
        build:
            context: ../../backend
            dockerfile: blog-service/Dockerfile
            target: production
        container_name: mankahi-blog-prod
        restart: unless-stopped
        working_dir: /app/blog-service
        env_file:
            - .env
        environment:
            - NODE_ENV=production
            - PORT=3002
            - ELASTICSEARCH_INDEX_SHARDS=3
            - ELASTICSEARCH_INDEX_REPLICAS=1
            - MINIO_ENDPOINT=minio
            - MINIO_PORT=9000
            - MINIO_USE_SSL=true
            - RATE_LIMIT_WINDOW=900
            - RATE_LIMIT_MAX_REQUESTS=100
            - BLOG_CACHE_TTL=3600
            - SEARCH_CACHE_TTL=300
            - MAX_FILE_SIZE=5242880
        volumes:
            - ../../backend/shared:/app/shared
            - blog-uploads:/app/blog-service/uploads
        deploy:
            replicas: 3
            update_config:
                parallelism: 1
                delay: 10s
            resources:
                limits:
                    cpus: "2"
                    memory: 2G
        healthcheck:
            test: ["CMD-SHELL", "curl -sf http://localhost:3002/health | grep -q '\"status\":\"healthy\"'"]
            interval: 30s
            timeout: 10s
            retries: 3
            start_period: 40s
        depends_on:
            elasticsearch:
                condition: service_healthy
            minio:
                condition: service_healthy
            redis:
                condition: service_healthy
            initdb:
                condition: service_completed_successfully
            postgres:
                condition: service_healthy
            analytics-service:
                condition: service_healthy
        ports:
            - "3002:3002"
        networks:
            - backend
        stop_grace_period: 30s
        logging:
            driver: "json-file"
            options:
                max-size: "200m"
                max-file: "5"

    # Analytics Service
    analytics-service:
        build:
            context: ../../backend
            dockerfile: analytics-service/Dockerfile
            target: production
        container_name: mankahi-analytics-prod
        restart: unless-stopped
        depends_on:
            init-db:
                condition: service_completed_successfully
            postgres:
                condition: service_healthy
            redis:
                condition: service_healthy
        working_dir: /app/analytics-service
        env_file:
            - .env
        environment:
            - NODE_ENV=production
            - PORT=3003
            - LOG_LEVEL=info
            - RATE_LIMIT_WINDOW=60000
            - RATE_LIMIT_MAX=60
            - DASHBOARD_RATE_LIMIT_MAX=300
        volumes:
            - ../../backend/shared:/app/shared
            - analytics-logs:/app/analytics-service/logs
        deploy:
            replicas: 2
            update_config:
                parallelism: 1
                delay: 10s
            resources:
                limits:
                    cpus: "1"
                    memory: 1G
        healthcheck:
            test: ["CMD-SHELL", "curl -sf http://localhost:3003/health | grep -q '\"status\":\"healthy\"'"]
            interval: 30s
            timeout: 10s
            retries: 3
            start_period: 40s
        ports:
            - "3003:3003"
        networks:
            - frontend
            - backend
        logging:
            driver: "json-file"
            options:
                max-size: "200m"
                max-file: "5"

    # Admin Service
    admin-service:
        build:
            context: ../../backend
            dockerfile: admin-service/Dockerfile
            target: production
        container_name: mankahi-admin-prod
        restart: unless-stopped
        depends_on:
            init-db:
                condition: service_completed_successfully
            postgres:
                condition: service_healthy
            redis:
                condition: service_healthy
            analytics-service:
                condition: service_healthy
        working_dir: /app/admin-service
        env_file:
            - .env
        environment:
            - NODE_ENV=production
            - PORT=3004
            - ADMIN_RATE_LIMIT_WINDOW=900000
            - ADMIN_RATE_LIMIT_MAX=100
            - LOG_LEVEL=info
        volumes:
            - ../../backend/shared:/app/shared
            - admin-logs:/app/admin-service/logs
        deploy:
            replicas: 2
            update_config:
                parallelism: 1
                delay: 10s
            resources:
                limits:
                    cpus: "1"
                    memory: 1G
        healthcheck:
            test: ["CMD-SHELL", "curl -sf http://localhost:3004/health | grep -q '\"status\":\"healthy\"'"]
            interval: 30s
            timeout: 10s
            retries: 3
            start_period: 40s
        ports:
            - "3004:3004"
        networks:
            - frontend
            - backend
        stop_grace_period: 30s
        logging:
            driver: "json-file"
            options:
                max-size: "200m"
                max-file: "5"

    # Frontend
    frontend:
        build:
            context: ../../frontend
            target: production
        container_name: mankahi-frontend-prod
        restart: unless-stopped
        depends_on:
            auth-service:
                condition: service_healthy
            blog-service:
                condition: service_healthy
            analytics-service:
                condition: service_healthy
            admin-service:
                condition: service_healthy
        env_file:
            - .env
        environment:
            - NODE_ENV=production
            - NUXT_PUBLIC_API_URL=http://localhost:80
        deploy:
            replicas: 3
            update_config:
                parallelism: 1
                delay: 10s
            resources:
                limits:
                    cpus: "1"
                    memory: 1G
        healthcheck:
            test: ["CMD-SHELL", "curl -sf http://localhost:3000"]
            interval: 30s
            timeout: 10s
            retries: 3
            start_period: 40s
        ports:
            - "3000:3000"
        networks:
            - frontend
        stop_grace_period: 30s
        logging:
            driver: "json-file"
            options:
                max-size: "200m"
                max-file: "5"

    # Prometheus
    prometheus:
        image: prom/prometheus:latest
        container_name: mankahi-prometheus-prod
        restart: unless-stopped
        volumes:
            - ../prometheus:/etc/prometheus
            - prometheus-data:/prometheus
        command:
            - --config.file=/etc/prometheus/prometheus.yml
            - --storage.tsdb.path=/prometheus
            - --storage.tsdb.retention.time=15d
            - --web.console.libraries=/usr/share/prometheus/console_libraries
            - --web.console.templates=/usr/share/prometheus/consoles
        depends_on:
            auth-service:
                condition: service_healthy
            blog-service:
                condition: service_healthy
            analytics-service:
                condition: service_healthy
            admin-service:
                condition: service_healthy
        ports:
            - "9090:9090"
        deploy:
            resources:
                limits:
                    cpus: "1"
                    memory: 2G
        healthcheck:
            test: ["CMD-SHELL", "wget -qO- http://localhost:9090/-/ready | grep -q 'Ready'"]
            interval: 30s
            timeout: 10s
            retries: 3
        networks:
            - backend
            - monitoring
        stop_grace_period: 30s
        logging:
            driver: "json-file"
            options:
                max-size: "200m"
                max-file: "5"

    # Grafana
    grafana:
        image: grafana/grafana-enterprise:latest
        container_name: mankahi-grafana-prod
        restart: unless-stopped
        volumes:
            - grafana-data:/var/lib/grafana
            - ../../kubernetes/base/dashboards:/var/lib/grafana/dashboards
        depends_on:
            prometheus:
                condition: service_healthy
        environment:
            - GF_SECURITY_ADMIN_USER=${GRAFANA_USER:-admin}
            - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD:-admin}
            - GF_AUTH_ANONYMOUS_ENABLED=false
            - GF_SERVER_ROOT_URL=http://localhost:3005
        ports:
            - "3005:3000"
        deploy:
            resources:
                limits:
                    cpus: "1"
                    memory: 1G
        healthcheck:
            test: ["CMD-SHELL", 'curl -sf http://localhost:3000/api/health | grep -q "  \"database\": \"ok\""']
            interval: 30s
            timeout: 10s
            retries: 3
        networks:
            - monitoring
        stop_grace_period: 30s
        logging:
            driver: "json-file"
            options:
                max-size: "200m"
                max-file: "5"

    # API Gateway
    nginx:
        image: nginx:latest
        container_name: mankahi-nginx-prod
        restart: unless-stopped
        ports:
            - "80:80"
            - "443:443"
        depends_on:
            frontend:
                condition: service_started
            auth-service:
                condition: service_healthy
            blog-service:
                condition: service_healthy
            analytics-service:
                condition: service_healthy
            admin-service:
                condition: service_healthy
        volumes:
            - ../nginx/nginx.conf:/etc/nginx/nginx.conf:ro
            - ../nginx/cors.conf:/etc/nginx/cors.conf:ro
            - ../nginx/ssl:/etc/nginx/ssl:ro
            - blog-uploads:/var/www/uploads
            - nginx-logs:/var/log/nginx
        deploy:
            replicas: 2
            update_config:
                parallelism: 1
                delay: 10s
            resources:
                limits:
                    cpus: "2"
                    memory: 2G
        healthcheck:
            test: ["CMD", "nginx", "-t"]
            interval: 30s
            timeout: 10s
            retries: 3
        networks:
            - frontend
            - backend
        stop_grace_period: 30s
        logging:
            driver: "json-file"
            options:
                max-size: "200m"
                max-file: "5"

volumes:
    postgres-data:
        driver: local
    redis-data:
        driver: local
    elasticsearch-data:
        driver: local
    minio-data:
        driver: local
    blog-uploads:
        driver: local
    analytics-logs:
        driver: local
    admin-logs:
        driver: local
    nginx-logs:
        driver: local
    prometheus-data:
        driver: local
    grafana-data:
        driver: local
